#!/usr/bin/env python3
"""
é‡æ’å™¨æ¨¡å— - åŸºç¡€ç‰ˆæœ¬
æä¾›åŸºæœ¬çš„é‡æ’åŠŸèƒ½
"""

import numpy as np
from sentence_transformers import CrossEncoder
import re
from collections import defaultdict


class SimpleReranker:
    """ç®€å•é‡æ’å™¨ï¼šåŸºäºå…³é”®è¯åŒ¹é…å’Œæ™ºèƒ½ä¸Šä¸‹æ–‡è§„åˆ™ - ç²¾ç¡®ä¼˜åŒ–ç‰ˆæœ¬"""
    
    def __init__(self, keywords=None, threshold=0.1):
        self.keywords = keywords or []
        self.threshold = threshold
        
        # å¢å¼ºçš„ä¸»é¢˜ç›¸å…³æƒé‡
        self.keyword_weights = {
            'ambition': 1.6, 'power': 1.5, 'desire': 1.4, 'guilt': 1.4,
            'fear': 1.3, 'love': 1.3, 'dream': 1.2, 'death': 1.5,
            'murder': 1.6, 'blood': 1.4, 'betrayal': 1.4, 'madness': 1.3,
            'conscience': 1.4, 'remorse': 1.3, 'shame': 1.2, 'honor': 1.2,
            'destiny': 1.2, 'fate': 1.3, 'prophecy': 1.3, 'crown': 1.4,
            'throne': 1.5, 'king': 1.3, 'queen': 1.3, 'evil': 1.4
        }
        
        # è¯­å¢ƒè´¨é‡æŒ‡æ ‡è¯æ±‡
        self.quality_indicators = {
            'high_literary': ['prophecy', 'portent', 'omen', 'vision', 'destiny', 'fate', 
                            'conscience', 'soul', 'spirit', 'heart', 'passion'],
            'dramatic_action': ['murder', 'kill', 'death', 'blood', 'revenge', 'betray',
                              'crown', 'throne', 'power', 'rule', 'command'],
            'emotional_depth': ['love', 'hate', 'fear', 'terror', 'grief', 'joy',
                               'despair', 'hope', 'rage', 'fury', 'guilt', 'shame'],
            'dialogue_markers': ['said', 'cried', 'whispered', 'shouted', 'replied',
                                'answered', 'asked', 'exclaimed', 'declared']
        }
        
        # è´Ÿé¢è´¨é‡æŒ‡æ ‡
        self.quality_detractors = [
            'stage direction', 'scene', 'act', 'enter', 'exit', 'exeunt',
            'aside', 'soliloquy', 'to the audience'
        ]
    
    def rerank(self, candidates, k=None):
        """è¶…ç²¾ç¡®å¤šç»´åº¦é‡æ’ - å¤§å¹…æå‡quoteç›¸å…³æ€§æ•æ‰èƒ½åŠ›"""
        if not candidates:
            return candidates
        
        print(f"ğŸ”„ ä½¿ç”¨è¶…ç²¾ç¡®å¤šç»´åº¦é‡æ’å™¨å¤„ç† {len(candidates)} ä¸ªå€™é€‰...")
        
        for candidate in candidates:
            content = candidate['content'].lower()
            found_keywords = candidate.get('found_keywords', [])
            original_content = candidate['content']  # ä¿ç•™åŸå§‹å¤§å°å†™ç”¨äºæŸäº›åˆ†æ
            word_count = len(content.split())
            
            # === ç¬¬ä¸€å±‚ï¼šå¢å¼ºçš„åŠ æƒå…³é”®è¯å¯†åº¦åˆ†æ ===
            weighted_keyword_score = 0
            total_keyword_frequency = 0
            keyword_context_bonus = 0
            
            for kw in found_keywords:
                kw_lower = kw.lower()
                weight = self.keyword_weights.get(kw_lower, 1.0)
                
                # å¤šç§åŒ¹é…æ–¹å¼è®¡ç®—é¢‘ç‡
                exact_freq = content.count(kw_lower)
                partial_freq = sum(1 for word in content.split() if kw_lower in word.lower())
                root_freq = sum(1 for word in content.split() if word.lower().startswith(kw_lower[:4]) and len(kw_lower) > 4)
                
                # ç»¼åˆé¢‘ç‡è®¡ç®—
                total_freq = exact_freq + partial_freq * 0.7 + root_freq * 0.4
                total_keyword_frequency += total_freq
                weighted_keyword_score += total_freq * weight
                
                # å…³é”®è¯ä¸Šä¸‹æ–‡è´¨é‡è¯„ä¼°
                if kw_lower in ['ambition', 'power', 'desire']:
                    power_contexts = ['throne', 'crown', 'king', 'queen', 'rule', 'control', 'authority', 'command']
                    context_matches = sum(1 for ctx in power_contexts if ctx in content)
                    keyword_context_bonus += context_matches * 0.15
                
                elif kw_lower in ['guilt', 'conscience', 'shame']:
                    moral_contexts = ['murder', 'blood', 'sin', 'wrong', 'evil', 'repent', 'forgive']
                    context_matches = sum(1 for ctx in moral_contexts if ctx in content)
                    keyword_context_bonus += context_matches * 0.2
                
                elif kw_lower in ['fear', 'terror', 'dread']:
                    fear_contexts = ['dark', 'horrible', 'dreadful', 'nightmare', 'death', 'murder']
                    context_matches = sum(1 for ctx in fear_contexts if ctx in content)
                    keyword_context_bonus += context_matches * 0.18
            
            # === ç¬¬äºŒå±‚ï¼šå…³é”®è¯å¤šæ ·æ€§å’Œåˆ†å¸ƒåˆ†æ ===
            unique_keywords = set(found_keywords)
            keyword_diversity = len(unique_keywords) / max(len(self.keywords), 1)
            
            # å…³é”®è¯åˆ†å¸ƒæƒé‡ - æ›´ç²¾ç¡®çš„ä½ç½®åˆ†æ
            position_weight = 0
            content_words = content.split()
            
            if len(content_words) > 0:
                for kw in found_keywords:
                    kw_positions = []
                    for i, word in enumerate(content_words):
                        if kw.lower() in word.lower():
                            kw_positions.append(i)
                    
                    for pos in kw_positions:
                        relative_pos = pos / len(content_words)
                        # æ›´ç»†è‡´çš„ä½ç½®æƒé‡åˆ†é…
                        if relative_pos < 0.1:  # å¼€å¤´10%
                            position_weight += 0.5
                        elif relative_pos > 0.9:  # ç»“å°¾10%
                            position_weight += 0.4
                        elif 0.4 <= relative_pos <= 0.6:  # ä¸­å¿ƒåŒºåŸŸ
                            position_weight += 0.3
                        elif relative_pos < 0.25 or relative_pos > 0.75:  # å‰å25%
                            position_weight += 0.2
                        else:
                            position_weight += 0.1
            
            # === ç¬¬ä¸‰å±‚ï¼šå†…å®¹è´¨é‡å’Œç»“æ„ç²¾ç¡®è¯„ä¼° ===
            # é•¿åº¦è´¨é‡è¯„åˆ†ï¼ˆæ›´ç²¾ç¡®çš„åŒºé—´ï¼‰
            if 25 <= word_count <= 60:      # ç†æƒ³é•¿åº¦
                length_score = 1.0
            elif 15 <= word_count <= 100:   # è‰¯å¥½é•¿åº¦
                length_score = 0.9
            elif 10 <= word_count <= 150:   # å¯æ¥å—é•¿åº¦
                length_score = 0.7
            elif word_count >= 5:           # æœ€å°å¯ç”¨é•¿åº¦
                length_score = 0.5
            else:
                length_score = 0.2           # è¿‡çŸ­å†…å®¹
            
            # === ç¬¬å››å±‚ï¼šæ·±åº¦æƒ…æ„Ÿå’Œæ–‡å­¦è´¨é‡åˆ†æ ===
            # æ‰©å±•çš„æƒ…æ„Ÿå¼ºåº¦è¯æ±‡
            high_intensity_words = [
                'overwhelming', 'consuming', 'burning', 'fierce', 'intense', 'powerful',
                'desperate', 'passionate', 'furious', 'terrifying', 'devastating', 'profound',
                'utter', 'complete', 'absolute', 'total', 'unbearable', 'excruciating'
            ]
            
            medium_intensity_words = [
                'strong', 'deep', 'significant', 'considerable', 'substantial', 'notable',
                'marked', 'serious', 'heavy', 'severe', 'acute', 'grave'
            ]
            
            literary_excellence_words = [
                'heart', 'soul', 'spirit', 'mind', 'conscience', 'breath', 'eyes', 'voice',
                'thought', 'feeling', 'emotion', 'memory', 'dream', 'vision', 'hope', 'fear'
            ]
            
            dramatic_power_words = [
                'murder', 'death', 'kill', 'blood', 'crown', 'throne', 'power', 'ambition',
                'guilt', 'betrayal', 'revenge', 'justice', 'fate', 'destiny', 'prophecy'
            ]
            
            # è®¡ç®—å„ç±»å¾—åˆ†
            high_intensity_count = sum(1 for word in high_intensity_words if word in content)
            medium_intensity_count = sum(1 for word in medium_intensity_words if word in content)
            literary_count = sum(1 for word in literary_excellence_words if word in content)
            dramatic_count = sum(1 for word in dramatic_power_words if word in content)
            
            # å½’ä¸€åŒ–æƒ…æ„Ÿå’Œæ–‡å­¦å¾—åˆ†
            intensity_score = min(1.0, (high_intensity_count * 0.4 + medium_intensity_count * 0.2))
            literary_score = min(1.0, literary_count / 4)
            dramatic_score = min(1.0, dramatic_count / 3)
            
            # === ç¬¬äº”å±‚ï¼šå¯¹è¯å’Œå™è¿°å¹³è¡¡åˆ†æ ===
            quote_indicators = content.count('"') + content.count("'")
            dialogue_verbs = ['said', 'replied', 'answered', 'asked', 'cried', 'whispered', 'shouted', 'exclaimed', 'declared', 'muttered']
            dialogue_verb_count = sum(1 for verb in dialogue_verbs if verb in content)
            
            dialogue_score = min(1.0, (quote_indicators * 0.1 + dialogue_verb_count * 0.2))
            
            # === ç¬¬å…­å±‚ï¼šè¯­å¢ƒè¿è´¯æ€§å’Œå®Œæ•´æ€§è¯„ä¼° ===
            coherence_score = 1.0
            
            # å¥å­å®Œæ•´æ€§æ£€æŸ¥
            if not content.strip().endswith(('.', '!', '?', '"', "'")):
                coherence_score *= 0.85
            
            # ç¢ç‰‡åŒ–æ£€æŸ¥
            sentence_count = len([s for s in content.split('.') if s.strip()])
            if sentence_count == 0:
                coherence_score *= 0.7
            elif word_count > 0 and word_count / max(sentence_count, 1) < 4:  # å¥å­è¿‡çŸ­
                coherence_score *= 0.9
            
            # å†…å®¹è¿è´¯æ€§æ£€æŸ¥
            if content.count(',') + content.count(';') + content.count(':') > word_count * 0.3:
                coherence_score *= 0.9  # æ ‡ç‚¹è¿‡å¤šå¯èƒ½è¡¨ç¤ºç¢ç‰‡åŒ–
            
            # === ç¬¬ä¸ƒå±‚ï¼šä¸»é¢˜ç›¸å…³æ€§æ·±åº¦åˆ†æ ===
            theme_relevance_bonus = 0
            
            # æ£€æŸ¥ä¸»é¢˜è¯æ±‡é›†ç¾¤
            theme_clusters = {
                'power_ambition': ['power', 'ambition', 'throne', 'crown', 'king', 'queen', 'rule', 'authority', 'control'],
                'guilt_conscience': ['guilt', 'conscience', 'shame', 'remorse', 'regret', 'sin', 'wrong', 'evil'],
                'love_passion': ['love', 'passion', 'heart', 'soul', 'devotion', 'affection', 'beloved'],
                'death_violence': ['death', 'murder', 'kill', 'blood', 'violence', 'grave', 'corpse'],
                'fear_terror': ['fear', 'terror', 'dread', 'horror', 'panic', 'frightened', 'afraid'],
                'supernatural': ['dream', 'vision', 'prophecy', 'ghost', 'spirit', 'weird', 'supernatural']
            }
            
            for theme_name, theme_words in theme_clusters.items():
                cluster_matches = sum(1 for word in theme_words if word in content)
                if cluster_matches >= 2:  # è‡³å°‘2ä¸ªç›¸å…³è¯æ±‡æ‰ç®—ä¸»é¢˜ç›¸å…³
                    theme_relevance_bonus += cluster_matches * 0.08
            
            # === ç»¼åˆè¯„åˆ†è®¡ç®— - ç²¾ç»†è°ƒæ•´çš„æƒé‡ç³»ç»Ÿ ===
            # å½’ä¸€åŒ–åŸºç¡€åˆ†æ•°
            normalized_keyword_score = weighted_keyword_score / max(word_count, 1)
            
            # æ·»åŠ æ–‡å­¦åˆ†æå¥–åŠ±
            literary_analysis_bonus = self._incorporate_literary_analysis(candidate)
            
            # å¤šç»´åº¦åˆ†æ•°ç»„åˆï¼ˆæƒé‡ç»è¿‡ç²¾å¿ƒè°ƒä¼˜ï¼‰
            base_score = 0.30 * normalized_keyword_score        # å…³é”®è¯å¯†åº¦åŸºç¡€åˆ†
            diversity_bonus = 0.15 * keyword_diversity          # å…³é”®è¯å¤šæ ·æ€§
            context_bonus = 0.12 * min(keyword_context_bonus, 1.0)  # å…³é”®è¯ä¸Šä¸‹æ–‡
            position_bonus = 0.10 * min(position_weight, 1.0)   # ä½ç½®æƒé‡
            quality_bonus = 0.08 * length_score                 # é•¿åº¦è´¨é‡
            intensity_bonus = 0.08 * intensity_score            # æƒ…æ„Ÿå¼ºåº¦
            literary_bonus = 0.07 * literary_score              # æ–‡å­¦è´¨é‡
            dramatic_bonus = 0.06 * dramatic_score              # æˆå‰§æ€§
            dialogue_bonus = 0.02 * dialogue_score              # å¯¹è¯å†…å®¹
            coherence_bonus = 0.02 * coherence_score            # è¿è´¯æ€§
            theme_bonus = min(theme_relevance_bonus, 0.15)      # ä¸»é¢˜ç›¸å…³æ€§å¥–åŠ±ï¼ˆä¸Šé™15%ï¼‰
            analysis_bonus = literary_analysis_bonus            # æ–‡å­¦åˆ†æå¥–åŠ±
            
            final_rerank_score = (base_score + diversity_bonus + context_bonus + position_bonus + 
                                quality_bonus + intensity_bonus + literary_bonus + 
                                dramatic_bonus + dialogue_bonus + coherence_bonus + theme_bonus + analysis_bonus)
            
            candidate['rerank_score'] = min(final_rerank_score, 1.0)
            
            # è¯¦ç»†å¾—åˆ†ä¿¡æ¯ï¼ˆç”¨äºè°ƒè¯•å’Œä¼˜åŒ–ï¼‰
            candidate['score_breakdown'] = {
                'keyword_density': base_score,
                'keyword_diversity': diversity_bonus,
                'keyword_context': context_bonus,
                'position_weight': position_bonus,
                'length_quality': quality_bonus,
                'emotional_intensity': intensity_bonus,
                'literary_quality': literary_bonus,
                'dramatic_elements': dramatic_bonus,
                'dialogue_content': dialogue_bonus,
                'coherence': coherence_bonus,
                'theme_relevance': theme_bonus,
                'literary_analysis': analysis_bonus,
                'total_keywords': len(found_keywords),
                'keyword_frequency': total_keyword_frequency,
                'word_count': word_count
            }
        
        # æŒ‰é‡æ’åˆ†æ•°æ’åº
        candidates.sort(key=lambda x: x.get('rerank_score', 0), reverse=True)
        
        if k is not None:
            candidates = candidates[:k]
        
        print(f"âœ… è¶…ç²¾ç¡®å¤šç»´åº¦é‡æ’å®Œæˆï¼Œè¿”å› {len(candidates)} ä¸ªé«˜è´¨é‡ç»“æœ")
        if candidates:
            top_score = candidates[0]['rerank_score']
            avg_score = np.mean([c['rerank_score'] for c in candidates])
            print(f"  é‡æ’åˆ†æ•°: æœ€é«˜({top_score:.3f}) å¹³å‡({avg_score:.3f})")
            
            # æ˜¾ç¤ºå¾—åˆ†åˆ†å¸ƒç»Ÿè®¡
            score_ranges = {'é«˜åˆ†(>0.7)': 0, 'ä¸­åˆ†(0.4-0.7)': 0, 'ä½åˆ†(<0.4)': 0}
            for c in candidates:
                score = c['rerank_score']
                if score > 0.7:
                    score_ranges['é«˜åˆ†(>0.7)'] += 1
                elif score > 0.4:
                    score_ranges['ä¸­åˆ†(0.4-0.7)'] += 1
                else:
                    score_ranges['ä½åˆ†(<0.4)'] += 1
            print(f"  å¾—åˆ†åˆ†å¸ƒ: {score_ranges}")
        
        return candidates

    def is_available(self):
        return True


class CrossEncoderReranker:
    """Cross-Encoderé‡æ’å™¨ - ä¼˜åŒ–ç‰ˆæœ¬ï¼Œæé«˜ç²¾ç¡®æ€§"""
    
    def __init__(self, model_name='cross-encoder/ms-marco-MiniLM-L-6-v2', threshold=0.1, keywords=None):
        self.model_name = model_name
        self.threshold = threshold
        self.keywords = keywords or []
        self.model = None
        
        # å¢å¼ºçš„ä¸»é¢˜ç›¸å…³æŸ¥è¯¢æ‰©å±•
        self.query_expansions = {
            'ambition': 'ambition desire for power seeking throne control authority dominion rule sovereignty',
            'power': 'power authority control dominion rule command sovereignty kingship monarchy crown throne',
            'guilt': 'guilt conscience remorse shame regret repentance sin wrong crime fault blame',
            'fear': 'fear terror dread anxiety horror panic apprehension fright alarm worry',
            'love': 'love passion affection devotion romance heart soul tender gentle sweet dear',
            'desire': 'desire want need craving longing yearning hunger thirst wish hope dream',
            'dream': 'dream vision nightmare prophecy sleep unconscious weird supernatural portent omen sign',
            'betrayal': 'betrayal treachery deceit disloyalty backstab false lie cheat trick deceive',
            'madness': 'madness insanity lunacy derangement mental illness crazy mad reason sanity mind',
            'death': 'death murder kill blood violence destruction grave tomb corpse ghost spirit',
            'murder': 'murder kill death blood violence crime sin evil wicked dark terrible',
            'blood': 'blood bloody murder kill death violence red stain guilt crime',
            'crown': 'crown throne king queen royal power authority rule sovereignty dominion',
            'conscience': 'conscience guilt remorse shame regret moral ethics virtue sin wrong'
        }
        
        # æ–‡å­¦è´¨é‡è¯„ä¼°æ ‡å‡†
        self.literary_quality_markers = {
            'metaphorical': ['like', 'as', 'seems', 'appears', 'resembles', 'symbol', 'metaphor'],
            'dramatic': ['terrible', 'horrible', 'dreadful', 'awful', 'fearful', 'dark', 'evil'],
            'emotional': ['passion', 'burning', 'consuming', 'overwhelming', 'intense', 'deep'],
            'philosophical': ['soul', 'spirit', 'mind', 'conscience', 'reason', 'thought', 'meditation']
        }
        
        try:
            print(f"æ­£åœ¨åŠ è½½Cross-Encoderæ¨¡å‹: {model_name}")
            # æ·»åŠ è®¾å¤‡å‚æ•°å’Œæ›´å®‰å…¨çš„åŠ è½½æ–¹å¼
            self.model = CrossEncoder(model_name, device='cpu', trust_remote_code=False)
            print(f"âœ… æ¨¡å‹ {model_name} åŠ è½½æˆåŠŸ")
        except Exception as e:
            print(f"âš ï¸ æ¨¡å‹ {model_name} åŠ è½½å¤±è´¥: {e}")
            
            # å°è¯•å¤‡ç”¨æ¨¡å‹
            backup_models = [
                'cross-encoder/ms-marco-TinyBERT-L-2-v2',
                'cross-encoder/ms-marco-MiniLM-L-2-v2'
            ]
            
            for backup_model in backup_models:
                if backup_model != model_name:
                    try:
                        print(f"ğŸ”„ å°è¯•å¤‡ç”¨æ¨¡å‹: {backup_model}")
                        self.model = CrossEncoder(backup_model, device='cpu', trust_remote_code=False)
                        print(f"âœ… å¤‡ç”¨æ¨¡å‹ {backup_model} åŠ è½½æˆåŠŸ")
                        self.model_name = backup_model
                        break
                    except Exception as e2:
                        print(f"âš ï¸ å¤‡ç”¨æ¨¡å‹ {backup_model} ä¹ŸåŠ è½½å¤±è´¥: {e2}")
                        continue
            
            if self.model is None:
                print("âŒ æ‰€æœ‰Cross-Encoderæ¨¡å‹éƒ½åŠ è½½å¤±è´¥ï¼Œå°†ä½¿ç”¨åŸºç¡€é‡æ’æ–¹æ³•")
                self.model = None
    
    def _build_enhanced_query(self, keywords):
        """æ„å»ºå¤šå±‚æ¬¡å¢å¼ºæŸ¥è¯¢ï¼Œå¤§å¹…æé«˜é‡æ’ç²¾ç¡®æ€§"""
        base_query = ' '.join(keywords)
        
        # 1. åŸºç¡€æŸ¥è¯¢æ‰©å±•
        expanded_terms = set()
        for keyword in keywords:
            keyword_lower = keyword.lower()
            if keyword_lower in self.query_expansions:
                expanded_terms.update(self.query_expansions[keyword_lower].split())
        
        # 2. æ„å»ºåˆ†å±‚æŸ¥è¯¢ç»“æ„
        queries = []
        
        # ä¸»æŸ¥è¯¢ï¼šç›´æ¥å…³é”®è¯åŒ¹é…
        queries.append(f"passages about {base_query}")
        
        # æ‰©å±•æŸ¥è¯¢ï¼šåŒ…å«ç›¸å…³æ¦‚å¿µ
        if expanded_terms:
            expanded_query = ' '.join(list(expanded_terms)[:10])  # é™åˆ¶æ‰©å±•è¯æ•°é‡
            queries.append(f"text containing themes of {base_query} including {expanded_query}")
        
        # æ–‡å­¦æ„ä¹‰æŸ¥è¯¢ï¼šå¼ºè°ƒæ–‡å­¦ä»·å€¼
        queries.append(f"literary passages with dramatic significance about {base_query}")
        
        # æƒ…æ„Ÿæ·±åº¦æŸ¥è¯¢ï¼šå¼ºè°ƒæƒ…æ„Ÿå†…å®¹
        queries.append(f"emotionally intense content about {base_query} with deep meaning")
        
        # è¿”å›ä¸»æŸ¥è¯¢ï¼ˆç”¨äºå…¼å®¹æ€§ï¼‰
        primary_query = queries[0]
        
        # å­˜å‚¨æ‰€æœ‰æŸ¥è¯¢ç”¨äºå¤šæŸ¥è¯¢è¯„ä¼°
        self._all_queries = queries
        
        return primary_query
    
    def _calculate_advanced_content_quality(self, content, found_keywords):
        """é«˜çº§å†…å®¹è´¨é‡è®¡ç®— - å¤šç»´åº¦ç²¾ç¡®è¯„ä¼°"""
        content_lower = content.lower()
        
        # 1. æ–‡å­¦è´¨é‡è¯„ä¼°
        literary_score = 0
        for category, markers in self.literary_quality_markers.items():
            matches = sum(1 for marker in markers if marker in content_lower)
            category_score = min(matches / 3, 1.0)  # å½’ä¸€åŒ–åˆ°0-1
            
            # åŠ æƒä¸åŒç±»åˆ«
            weights = {'metaphorical': 0.3, 'dramatic': 0.3, 'emotional': 0.25, 'philosophical': 0.15}
            literary_score += category_score * weights.get(category, 0.25)
        
        # 2. å…³é”®è¯è¯­å¢ƒè´¨é‡
        context_quality = 0
        for keyword in found_keywords:
            keyword_lower = keyword.lower()
            
            # æ£€æŸ¥å…³é”®è¯çš„ä¸Šä¸‹æ–‡ä½¿ç”¨
            if keyword_lower in self.query_expansions:
                expansion_words = self.query_expansions[keyword_lower].split()
                context_matches = sum(1 for word in expansion_words if word in content_lower)
                context_ratio = context_matches / len(expansion_words)
                context_quality += context_ratio
        
        if found_keywords:
            context_quality /= len(found_keywords)
        
        # 3. ç»“æ„å®Œæ•´æ€§è¯„ä¼°
        structural_quality = 1.0
        word_count = len(content.split())
        
        # é•¿åº¦é€‚ä¸­æ€§
        if word_count < 10:
            structural_quality *= 0.6
        elif word_count > 200:
            structural_quality *= 0.8
        elif 20 <= word_count <= 100:
            structural_quality *= 1.0
        else:
            structural_quality *= 0.9
        
        # å®Œæ•´æ€§æ£€æŸ¥
        if not content.strip().endswith(('.', '!', '?', '"', "'")):
            structural_quality *= 0.8
        
        # 4. å¯¹è¯å’Œå™è¿°å¹³è¡¡
        dialogue_markers = sum(1 for marker in ['"', "'", 'said', 'replied'] if marker in content_lower)
        narrative_markers = sum(1 for marker in ['he', 'she', 'it', 'they', 'was', 'were'] if marker in content_lower)
        balance_score = 1.0
        if dialogue_markers > 0 or narrative_markers > 0:
            total_markers = dialogue_markers + narrative_markers
            if total_markers > 0:
                dialogue_ratio = dialogue_markers / total_markers
                # ç†æƒ³çš„å¯¹è¯-å™è¿°æ¯”ä¾‹
                if 0.2 <= dialogue_ratio <= 0.8:
                    balance_score = 1.0
                else:
                    balance_score = 0.8
        
        # ç»¼åˆè´¨é‡åˆ†æ•°
        final_quality = (
            0.35 * literary_score +
            0.30 * context_quality +
            0.20 * structural_quality +
            0.15 * balance_score
        )
        
        return min(final_quality, 1.0)
    
    def _calculate_content_quality_score(self, content, found_keywords):
        """è®¡ç®—å†…å®¹è´¨é‡åˆ†æ•°"""
        content_lower = content.lower()
        
        # æ–‡å­¦è´¨é‡æŒ‡æ ‡
        literary_indicators = [
            'said', 'cried', 'whispered', 'shouted', 'exclaimed', 'replied',
            'thought', 'felt', 'saw', 'heard', 'knew', 'believed',
            'heart', 'soul', 'mind', 'spirit', 'eyes', 'face'
        ]
        
        dramatic_indicators = [
            'terrible', 'horrible', 'dreadful', 'fierce', 'burning', 'consuming',
            'overwhelming', 'desperate', 'intense', 'powerful', 'deep', 'strong',
            'evil', 'wicked', 'dark', 'bloody', 'murder', 'death', 'kill'
        ]
        
        dialogue_indicators = ['"', "'", 'said', 'replied', 'answered', 'asked']
        
        # è®¡ç®—å„ç§æŒ‡æ ‡
        literary_score = sum(1 for word in literary_indicators if word in content_lower) / len(literary_indicators)
        dramatic_score = sum(1 for word in dramatic_indicators if word in content_lower) / len(dramatic_indicators)
        dialogue_score = sum(1 for indicator in dialogue_indicators if indicator in content_lower) / len(dialogue_indicators)
        
        # å…³é”®è¯é›†ä¸­åº¦
        keyword_density = len(found_keywords) / max(len(content.split()), 1)
        
        # ç»¼åˆè´¨é‡åˆ†æ•°
        quality_score = 0.3 * literary_score + 0.4 * dramatic_score + 0.2 * dialogue_score + 0.1 * keyword_density
        
        return min(quality_score, 1.0)
    
    def rerank(self, candidates, k=None):
        """
        ç»ˆæç²¾ç¡®Cross-Encoderé‡æ’ - å¤šæŸ¥è¯¢å˜ä½“ + æ·±åº¦è´¨é‡èåˆ
        å®ç°æœ€ç²¾ç¡®çš„quoteç›¸å…³æ€§åˆ¤æ–­å’Œæ–‡å­¦ä»·å€¼è¯„ä¼°
        """
        if not self.model or not candidates:
            return candidates
        
        print(f"ï¿½ ä½¿ç”¨ç»ˆæç²¾ç¡®Cross-Encoderé‡æ’å™¨å¤„ç† {len(candidates)} ä¸ªå€™é€‰...")
        
        try:
            # === æ„å»ºå¤šå±‚æ¬¡æŸ¥è¯¢ä½“ç³» ===
            primary_query = ' '.join(self.keywords)
            enhanced_query = self._build_enhanced_query(self.keywords)
            
            # é«˜çº§æŸ¥è¯¢å˜ä½“ - æ•æ‰ä¸åŒå±‚é¢çš„ç›¸å…³æ€§
            query_variants = [
                primary_query,  # åŸºç¡€æŸ¥è¯¢
                enhanced_query,  # æ‰©å±•æŸ¥è¯¢
                f"literary passages about {primary_query} with deep meaning",  # æ–‡å­¦æ·±åº¦
                f"dramatic and significant quotes about {primary_query}",  # æˆå‰§æ€§
                f"emotionally powerful text containing {primary_query}",  # æƒ…æ„Ÿå¼ºåº¦
                f"thematically relevant content about {primary_query}",  # ä¸»é¢˜ç›¸å…³
                f"contextually meaningful {primary_query} in literature"  # è¯­å¢ƒæ„ä¹‰
            ]
            
            # ä¸ºæ¯ä¸ªå€™é€‰ç”Ÿæˆå¤šä¸ªæŸ¥è¯¢-æ–‡æœ¬å¯¹
            query_text_pairs = []
            candidate_indices = []
            query_types = []
            
            for i, item in enumerate(candidates):
                content = item['content']
                
                for j, query in enumerate(query_variants):
                    query_text_pairs.append((query, content))
                    candidate_indices.append(i)
                    query_types.append(j)
            
            print(f"  ç”Ÿæˆ {len(query_text_pairs)} ä¸ªå¤šç»´åº¦æŸ¥è¯¢-æ–‡æœ¬å¯¹è¿›è¡Œæ·±åº¦è¯„ä¼°...")
            
            # æ‰¹é‡é¢„æµ‹ç›¸å…³æ€§åˆ†æ•°ï¼ˆä½¿ç”¨è¾ƒå°çš„batch_sizeç¡®ä¿ç¨³å®šæ€§ï¼‰
            batch_size = min(32, len(query_text_pairs))
            all_scores = []
            
            for i in range(0, len(query_text_pairs), batch_size):
                batch_pairs = query_text_pairs[i:i + batch_size]
                batch_scores = self.model.predict(batch_pairs, show_progress_bar=False)
                all_scores.extend(batch_scores)
            
            # === æ™ºèƒ½åˆ†æ•°èšåˆå’Œèåˆ ===
            candidate_scores = defaultdict(lambda: defaultdict(list))
            
            # æŒ‰å€™é€‰å’ŒæŸ¥è¯¢ç±»å‹åˆ†ç»„åˆ†æ•°
            for score, candidate_idx, query_type in zip(all_scores, candidate_indices, query_types):
                candidate_scores[candidate_idx][query_type].append(max(0.0, float(score)))
            
            # è®¡ç®—æ¯ä¸ªå€™é€‰çš„å¤šç»´åº¦ç»¼åˆåˆ†æ•°
            for i, candidate in enumerate(candidates):
                if i in candidate_scores:
                    scores_by_type = candidate_scores[i]
                    
                    # ä¸åŒæŸ¥è¯¢ç±»å‹çš„ç²¾ç»†åŒ–æƒé‡
                    query_weights = [0.25, 0.20, 0.15, 0.12, 0.10, 0.10, 0.08]
                    
                    # è®¡ç®—åŠ æƒCross-Encoderåˆ†æ•°
                    weighted_ce_score = 0
                    total_weight = 0
                    
                    for query_type, weight in enumerate(query_weights):
                        if query_type in scores_by_type and scores_by_type[query_type]:
                            type_score = np.mean(scores_by_type[query_type])
                            weighted_ce_score += type_score * weight
                            total_weight += weight
                    
                    if total_weight > 0:
                        weighted_ce_score /= total_weight
                    
                    # è®¡ç®—åˆ†æ•°å˜å¼‚æ€§ï¼ˆä¸€è‡´æ€§æŒ‡æ ‡ï¼‰
                    all_candidate_scores = []
                    for type_scores in scores_by_type.values():
                        all_candidate_scores.extend(type_scores)
                    
                    if all_candidate_scores:
                        score_std = np.std(all_candidate_scores)
                        score_consistency = 1.0 - min(score_std, 0.5)  # åˆ†æ•°è¶Šä¸€è‡´ï¼Œæƒé‡è¶Šé«˜
                    else:
                        score_consistency = 0.0
                    
                    candidate['multi_query_ce_score'] = weighted_ce_score
                    candidate['score_consistency'] = score_consistency
                else:
                    candidate['multi_query_ce_score'] = 0.0
                    candidate['score_consistency'] = 0.0
                
                # === æ·±åº¦å†…å®¹è´¨é‡åˆ†æ ===
                content = candidate['content']
                found_keywords = candidate.get('found_keywords', [])
                similarity_score = candidate.get('similarity_score', 0)
                
                # é«˜çº§å†…å®¹è´¨é‡è¯„ä¼°
                content_quality = self._calculate_advanced_content_quality(content, found_keywords)
                
                # ç»“æ„å’Œå®Œæ•´æ€§è¯„ä¼°
                structural_quality = self._evaluate_structural_integrity(content)
                
                # æ–‡å­¦ä»·å€¼å’Œæ·±åº¦è¯„ä¼°
                literary_depth = self._evaluate_literary_depth(content, found_keywords)
                
                # ä¸»é¢˜ä¸€è‡´æ€§å’Œç›¸å…³æ€§
                thematic_relevance = self._evaluate_thematic_relevance(content, found_keywords)
                
                # æƒ…æ„Ÿå¼ºåº¦å’Œæˆå‰§æ•ˆæœ
                emotional_impact = self._evaluate_emotional_impact(content)
                
                # === å¤šç»´åº¦åˆ†æ•°èåˆ ===
                # åŸºç¡€ç›¸ä¼¼åº¦ç»„ä»¶
                similarity_component = similarity_score * 0.12
                
                # Cross-Encoderç»„ä»¶ï¼ˆä¸»è¦æƒé‡ï¼‰
                ce_component = candidate['multi_query_ce_score'] * 0.40
                
                # åˆ†æ•°ä¸€è‡´æ€§å¥–åŠ±
                consistency_component = candidate['score_consistency'] * 0.05
                
                # å†…å®¹è´¨é‡ç»„ä»¶
                quality_component = content_quality * 0.18
                
                # ç»“æ„è´¨é‡ç»„ä»¶
                structure_component = structural_quality * 0.08
                
                # æ–‡å­¦æ·±åº¦ç»„ä»¶
                literary_component = literary_depth * 0.08
                
                # ä¸»é¢˜ç›¸å…³æ€§ç»„ä»¶
                theme_component = thematic_relevance * 0.06
                
                # æƒ…æ„Ÿå½±å“ç»„ä»¶
                emotion_component = emotional_impact * 0.03
                
                # æœ€ç»ˆç»¼åˆåˆ†æ•°
                final_score = (similarity_component + ce_component + consistency_component +
                              quality_component + structure_component + literary_component + 
                              theme_component + emotion_component)
                
                candidate['rerank_score'] = min(final_score, 1.0)
                
                # è¯¦ç»†è¯„åˆ†åˆ†è§£ï¼ˆç”¨äºåˆ†æå’Œè°ƒè¯•ï¼‰
                candidate['score_breakdown'] = {
                    'similarity_base': similarity_component,
                    'multi_query_ce': ce_component,
                    'score_consistency': consistency_component,
                    'content_quality': quality_component,
                    'structural_quality': structure_component,
                    'literary_depth': literary_component,
                    'thematic_relevance': theme_component,
                    'emotional_impact': emotion_component,
                    'final_score': final_score
                }
            
        except Exception as e:
            print(f"âš ï¸ Cross-Encoderæ‰¹é‡è¯„ä¼°å¤±è´¥: {e}")
            # å›é€€åˆ°é€ä¸ªå¤„ç†
            self._fallback_individual_processing(candidates)
        
        # æŒ‰æœ€ç»ˆé‡æ’åˆ†æ•°æ’åº
        candidates.sort(key=lambda x: x.get('rerank_score', 0), reverse=True)
        
        if k is not None:
            candidates = candidates[:k]
        
        print(f"âœ… ç»ˆæç²¾ç¡®Cross-Encoderé‡æ’å®Œæˆï¼Œè¿”å› {len(candidates)} ä¸ªé¡¶çº§ç»“æœ")
        
        if candidates:
            top_score = candidates[0]['rerank_score']
            avg_score = np.mean([c['rerank_score'] for c in candidates])
            top_ce_score = candidates[0].get('multi_query_ce_score', 0)
            avg_ce_score = np.mean([c.get('multi_query_ce_score', 0) for c in candidates])
            
            print(f"  æœ€ç»ˆåˆ†æ•°: æœ€é«˜({top_score:.3f}) å¹³å‡({avg_score:.3f})")
            print(f"  å¤šæŸ¥è¯¢CEåˆ†æ•°: æœ€é«˜({top_ce_score:.3f}) å¹³å‡({avg_ce_score:.3f})")
            
            # è´¨é‡åˆ†å¸ƒåˆ†æ
            excellence_tier = len([c for c in candidates if c['rerank_score'] > 0.8])
            high_quality = len([c for c in candidates if 0.6 <= c['rerank_score'] <= 0.8])
            medium_quality = len([c for c in candidates if 0.4 <= c['rerank_score'] < 0.6])
            
            print(f"  è´¨é‡åˆ†å¸ƒ: å“è¶Š({excellence_tier}) é«˜è´¨é‡({high_quality}) ä¸­ç­‰({medium_quality}) å…¶ä»–({len(candidates)-excellence_tier-high_quality-medium_quality})")
        
        return candidates
    
    def _evaluate_structural_integrity(self, content):
        """è¯„ä¼°æ–‡æœ¬ç»“æ„å®Œæ•´æ€§"""
        words = content.split()
        word_count = len(words)
        
        # é•¿åº¦é€‚ä¸­æ€§è¯„åˆ†
        if 20 <= word_count <= 80:
            length_score = 1.0
        elif 15 <= word_count <= 120:
            length_score = 0.85
        elif 10 <= word_count <= 150:
            length_score = 0.7
        else:
            length_score = 0.5
        
        # å®Œæ•´æ€§è¯„åˆ†
        completeness_score = 1.0 if content.strip().endswith(('.', '!', '?', '"', "'")) else 0.8
        
        # å¥å­ç»“æ„è¯„åˆ†
        sentences = [s.strip() for s in content.split('.') if s.strip()]
        if sentences:
            avg_sentence_length = word_count / len(sentences)
            if 8 <= avg_sentence_length <= 25:
                structure_score = 1.0
            else:
                structure_score = 0.8
        else:
            structure_score = 0.6
        
        return (length_score + completeness_score + structure_score) / 3
    
    def _evaluate_literary_depth(self, content, found_keywords):
        """è¯„ä¼°æ–‡å­¦æ·±åº¦å’Œè‰ºæœ¯ä»·å€¼"""
        content_lower = content.lower()
        
        # æ–‡å­¦è®¾å¤‡æ£€æµ‹
        literary_devices = [
            'metaphor', 'simile', 'imagery', 'symbol', 'symbolism', 'irony', 'paradox',
            'foreshadowing', 'allegory', 'personification', 'dramatic', 'tragic'
        ]
        
        # æ·±åº¦æƒ…æ„Ÿè¯æ±‡
        profound_emotions = [
            'anguish', 'ecstasy', 'despair', 'rapture', 'torment', 'bliss',
            'melancholy', 'euphoria', 'desolation', 'transcendence'
        ]
        
        # å“²å­¦å’Œå¿ƒç†è¯æ±‡
        philosophical_terms = [
            'soul', 'spirit', 'conscience', 'consciousness', 'existence', 'mortality',
            'destiny', 'fate', 'meaning', 'purpose', 'truth', 'reality'
        ]
        
        device_count = sum(1 for device in literary_devices if device in content_lower)
        emotion_count = sum(1 for emotion in profound_emotions if emotion in content_lower)
        philosophy_count = sum(1 for term in philosophical_terms if term in content_lower)
        
        # ç»¼åˆæ–‡å­¦æ·±åº¦åˆ†æ•°
        literary_score = min((device_count * 0.3 + emotion_count * 0.4 + philosophy_count * 0.3), 1.0)
        
        return literary_score
    
    def _evaluate_thematic_relevance(self, content, found_keywords):
        """è¯„ä¼°ä¸»é¢˜ç›¸å…³æ€§å’Œä¸€è‡´æ€§"""
        content_lower = content.lower()
        
        # ä¸»é¢˜è¯æ±‡é›†ç¾¤
        theme_clusters = {
            'power_ambition': ['power', 'ambition', 'throne', 'crown', 'king', 'queen', 'rule', 'authority', 'control', 'dominion'],
            'moral_guilt': ['guilt', 'conscience', 'shame', 'remorse', 'sin', 'wrong', 'evil', 'repent', 'forgive'],
            'love_passion': ['love', 'passion', 'heart', 'soul', 'beloved', 'devotion', 'affection', 'romance'],
            'death_violence': ['death', 'murder', 'kill', 'blood', 'violence', 'grave', 'corpse', 'ghost'],
            'fear_terror': ['fear', 'terror', 'dread', 'horror', 'panic', 'frightened', 'afraid'],
            'fate_destiny': ['fate', 'destiny', 'doom', 'prophecy', 'future', 'inevitable', 'predetermined']
        }
        
        # è®¡ç®—ä¸»é¢˜ä¸€è‡´æ€§
        max_cluster_score = 0
        for cluster_name, cluster_words in theme_clusters.items():
            cluster_matches = sum(1 for word in cluster_words if word in content_lower)
            if cluster_matches >= 2:  # è‡³å°‘2ä¸ªç›¸å…³è¯æ‰ç®—ä¸»é¢˜ä¸€è‡´
                cluster_score = min(cluster_matches / len(cluster_words), 0.8)
                max_cluster_score = max(max_cluster_score, cluster_score)
        
        # å…³é”®è¯å¯†åº¦å¥–åŠ±
        keyword_density = len(found_keywords) / max(len(content.split()), 1)
        density_score = min(keyword_density * 10, 0.3)  # æœ€å¤š30%å¥–åŠ±
        
        return max_cluster_score + density_score
    
    def _evaluate_emotional_impact(self, content):
        """è¯„ä¼°æƒ…æ„Ÿå†²å‡»åŠ›å’Œæˆå‰§æ•ˆæœ"""
        content_lower = content.lower()
        
        # é«˜å†²å‡»æƒ…æ„Ÿè¯æ±‡
        high_impact_emotions = [
            'overwhelming', 'devastating', 'crushing', 'shattering', 'excruciating',
            'unbearable', 'agonizing', 'heart-wrenching', 'soul-crushing'
        ]
        
        # æˆå‰§æ€§åŠ¨ä½œè¯æ±‡
        dramatic_actions = [
            'murder', 'kill', 'betray', 'deceive', 'destroy', 'shatter', 'crush',
            'reveal', 'discover', 'confront', 'confess', 'expose'
        ]
        
        # å¼ºåº¦å‰¯è¯
        intensity_adverbs = [
            'utterly', 'completely', 'absolutely', 'totally', 'entirely',
            'deeply', 'profoundly', 'intensely', 'desperately'
        ]
        
        impact_count = sum(1 for word in high_impact_emotions if word in content_lower)
        drama_count = sum(1 for word in dramatic_actions if word in content_lower)
        intensity_count = sum(1 for word in intensity_adverbs if word in content_lower)
        
        # ç»¼åˆæƒ…æ„Ÿå†²å‡»åˆ†æ•°
        emotional_score = min((impact_count * 0.4 + drama_count * 0.3 + intensity_count * 0.3), 1.0)
        
        return emotional_score
    
    def _fallback_individual_processing(self, candidates):
        """å›é€€å¤„ç†ï¼šé€ä¸ªå¤„ç†å€™é€‰"""
        print("  å›é€€åˆ°é€ä¸ªå¤„ç†æ¨¡å¼...")
        primary_query = ' '.join(self.keywords)
        
        for candidate in candidates:
            try:
                content = candidate['content']
                pairs = [(primary_query, content)]
                scores = self.model.predict(pairs)
                
                ce_score = float(scores[0]) if isinstance(scores, np.ndarray) else float(scores)
                candidate['multi_query_ce_score'] = max(0.0, ce_score)
                candidate['score_consistency'] = 1.0  # å•æŸ¥è¯¢é»˜è®¤ä¸€è‡´æ€§é«˜
                
            except Exception as e:
                print(f"âš ï¸ ä¸ªåˆ«å€™é€‰å¤„ç†å¤±è´¥: {e}")
                candidate['multi_query_ce_score'] = 0.0
                candidate['score_consistency'] = 0.0

    def is_available(self):
        """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å¯ç”¨"""
        return self.model is not None
    
    def _calculate_keyword_relevance_score(self, content, found_keywords):
        """è®¡ç®—å…³é”®è¯ç›¸å…³æ€§åˆ†æ•°"""
        if not found_keywords:
            return 0.0
        
        content_lower = content.lower()
        
        # å…³é”®è¯å¯†åº¦
        keyword_density = len(found_keywords) / max(len(content.split()), 1)
        
        # å…³é”®è¯å¤šæ ·æ€§
        unique_keywords = len(set([kw.lower() for kw in found_keywords]))
        keyword_diversity = unique_keywords / max(len(self.keywords), 1)
        
        # å…³é”®è¯ä¸Šä¸‹æ–‡å¼ºåº¦
        context_strength = 0
        for kw in found_keywords:
            if kw.lower() in self.query_expansions:
                expansion_words = self.query_expansions[kw.lower()].split()
                context_matches = sum(1 for word in expansion_words if word in content_lower)
                context_strength += context_matches / len(expansion_words)
        
        context_strength = context_strength / max(len(found_keywords), 1)
        
        # ç»¼åˆåˆ†æ•°
        relevance_score = 0.4 * keyword_density + 0.3 * keyword_diversity + 0.3 * context_strength
        return min(relevance_score * 5, 1.0)  # æ”¾å¤§åˆ†æ•°ä½†é™åˆ¶åœ¨1.0ä»¥å†…
    
    def _calculate_structural_quality_score(self, content):
        """è®¡ç®—ç»“æ„è´¨é‡åˆ†æ•°"""
        # é•¿åº¦é€‚ä¸­æ€§
        word_count = len(content.split())
        if 15 <= word_count <= 100:
            length_score = 1.0
        elif 10 <= word_count <= 150:
            length_score = 0.8
        else:
            length_score = 0.6
        
        # å®Œæ•´æ€§ï¼ˆæ˜¯å¦æœ‰å®Œæ•´çš„å¥å­ç»“æ„ï¼‰
        completeness_score = 1.0
        if not content.strip().endswith(('.', '!', '?', '"', "'")):
            completeness_score *= 0.8
        
        # æ ‡ç‚¹ç¬¦å·çš„åˆç†æ€§
        punctuation_count = sum(1 for char in content if char in '.!?;:,')
        punctuation_ratio = punctuation_count / max(word_count, 1)
        if 0.05 <= punctuation_ratio <= 0.3:
            punctuation_score = 1.0
        else:
            punctuation_score = 0.7
        
        return 0.5 * length_score + 0.3 * completeness_score + 0.2 * punctuation_score
    
    def _calculate_retrieval_confidence(self, item):
        """åŸºäºæ£€ç´¢é˜¶æ®µä¿¡æ¯è®¡ç®—ä¿¡å¿ƒåˆ†æ•°"""
        confidence = 0.5  # åŸºç¡€åˆ†æ•°
        
        # å¦‚æœæœ‰similarity_score
        if 'similarity_score' in item:
            sim_score = item['similarity_score']
            if sim_score > 0.5:
                confidence += 0.3
            elif sim_score > 0.3:
                confidence += 0.2
            elif sim_score > 0.1:
                confidence += 0.1
        
        # å¦‚æœæœ‰æ£€ç´¢é˜¶æ®µä¿¡æ¯
        if 'stage' in item:
            stage = item['stage']
            if stage == 'high_quality':
                confidence += 0.2
            elif stage == 'balanced':
                confidence += 0.1
        
        # å¦‚æœæœ‰å¤šç§åŒ¹é…ç±»å‹
        if item.get('found_keywords') and 'similarity_score' in item:
            if item['similarity_score'] > 0.2:  # æ··åˆåŒ¹é…
                confidence += 0.1
        
        return min(confidence, 1.0)
    
    def is_available(self):
        return self.model is not None
    
    def _incorporate_literary_analysis(self, candidate):
        """åˆ©ç”¨æ–‡å­¦åˆ†æç»“æœæå‡é‡æ’ç²¾åº¦"""
        literary_analysis = candidate.get('literary_analysis', {})
        if not literary_analysis:
            return 0
        
        literary_bonus = 0
        
        # ä¸»é¢˜å…ƒç´ ç›¸å…³æ€§å¥–åŠ±
        themes = literary_analysis.get('thematic_elements', {})
        if themes:
            # æ£€æŸ¥ä¸»é¢˜ä¸æœç´¢å…³é”®è¯çš„åŒ¹é…åº¦
            search_theme_alignment = themes.get('search_theme_alignment', {})
            if search_theme_alignment:
                # ç»™äºˆä¸»é¢˜å¯¹é½å¥–åŠ±
                avg_theme_relevance = sum(search_theme_alignment.values()) / len(search_theme_alignment)
                literary_bonus += avg_theme_relevance * 0.3
            
            # é‡è¦ä¸»é¢˜æ£€æµ‹å¥–åŠ±
            important_themes = ['power_and_ambition', 'guilt_and_conscience', 'fate_and_destiny']
            theme_count = sum(1 for theme in important_themes if theme in themes)
            if theme_count > 0:
                literary_bonus += theme_count * 0.1
        
        # è¯­è¨€æ¨¡å¼å¤æ‚åº¦å¥–åŠ±
        patterns = literary_analysis.get('linguistic_patterns', {})
        if patterns:
            # ä¿®è¾ç–‘é—®å’Œé‡å¤æ¨¡å¼å¥–åŠ±
            if patterns.get('rhetorical_questions'):
                literary_bonus += 0.15
            if patterns.get('repetition_patterns'):
                literary_bonus += 0.1
            
            # å¥æ³•å¤æ‚åº¦å¥–åŠ±
            syntactic_complexity = patterns.get('syntactic_complexity', {})
            if syntactic_complexity.get('complex_sentence_indicators'):
                literary_bonus += 0.12
        
        # å™äº‹ç»“æ„è´¨é‡å¥–åŠ±
        narrative = literary_analysis.get('narrative_structure', {})
        if narrative:
            # å¯¹è¯è´¨é‡å¥–åŠ±
            if narrative.get('has_dialogue'):
                dialogue_intensity = narrative.get('dialogue_intensity', 0)
                if dialogue_intensity > 0.1:  # é«˜å¯¹è¯å¯†åº¦
                    literary_bonus += 0.15
            
            # å™äº‹é£æ ¼å¹³è¡¡å¥–åŠ±
            style = narrative.get('narrative_style', '')
            if style in ['action_oriented', 'descriptive_oriented']:
                literary_bonus += 0.08
        
        # äº‹å®è§‚å¯Ÿè´¨é‡å¥–åŠ±
        observations = literary_analysis.get('factual_observations', [])
        if observations:
            # åŸºäºè§‚å¯Ÿçš„æ•°é‡å’Œç±»å‹ç»™äºˆå¥–åŠ±
            high_quality_obs = [obs for obs in observations if any(keyword in obs for keyword in ['å¯†åº¦', 'å¼ºçƒˆ', 'å¤æ‚', 'ä¸»é¢˜'])]
            if high_quality_obs:
                literary_bonus += len(high_quality_obs) * 0.05
            
            # ç‰¹æ®Šè§‚å¯Ÿå¥–åŠ±
            for obs in observations:
                if 'ä¸»é¢˜' in obs:
                    literary_bonus += 0.1
                if 'å¤æ‚' in obs:
                    literary_bonus += 0.08
                if 'å¼ºçƒˆ' in obs:
                    literary_bonus += 0.07
        
        return min(literary_bonus, 0.5)  # é™åˆ¶æœ€å¤§å¥–åŠ±ä¸º0.5


def create_reranker(method="cross_encoder", keywords=None, **kwargs):
    """å·¥å‚å‡½æ•°ï¼šåˆ›å»ºé‡æ’å™¨ï¼ŒåŒ…æ‹¬åŸºç¡€å’Œå¢å¼ºç‰ˆ - ä¼˜åŒ–ç‰ˆæœ¬"""
    
    # é«˜çº§ä¸Šä¸‹æ–‡æ„ŸçŸ¥é‡æ’å™¨ï¼ˆä¸“ä¸ºæ–‡å­¦ä½œå“ä¼˜åŒ–ï¼‰
    if method == "advanced_context_aware":
        from .reranker_enhanced import create_enhanced_reranker
        return create_enhanced_reranker(method="advanced_context_aware", keywords=keywords, **kwargs)
    
    # å¢å¼ºç‰ˆé‡æ’å™¨æ”¯æŒ
    elif method == "enhanced_cross_encoder":
        from .reranker_enhanced import create_enhanced_reranker
        return create_enhanced_reranker(method=method, keywords=keywords, **kwargs)
    
    # å¤šæ¨¡å‹ensembleé‡æ’å™¨
    elif method == "ensemble":
        from .reranker_enhanced import create_enhanced_reranker
        return create_enhanced_reranker(method="ensemble", keywords=keywords, **kwargs)
    
    # å¤šæ ·æ€§ä¼˜åŒ–é‡æ’å™¨
    elif method == "diversity_optimizer":
        from .reranker_enhanced import create_enhanced_reranker
        return create_enhanced_reranker(method="diversity_optimizer", keywords=keywords, **kwargs)
    
    # åŸºç¡€ Cross-Encoder é‡æ’å™¨ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰
    elif method == "cross_encoder":
        return CrossEncoderReranker(keywords=keywords, **kwargs)
    
    # ç®€å•é‡æ’å™¨ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰
    elif method == "simple":
        return SimpleReranker(keywords=keywords, **kwargs)
    
    # é»˜è®¤ä½¿ç”¨é«˜çº§ä¸Šä¸‹æ–‡æ„ŸçŸ¥é‡æ’å™¨ï¼ˆæœ€é€‚åˆæ–‡å­¦ä½œå“æ£€ç´¢ï¼‰
    else:
        from .reranker_enhanced import create_enhanced_reranker
        return create_enhanced_reranker(method="advanced_context_aware", keywords=keywords, **kwargs)
